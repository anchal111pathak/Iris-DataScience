{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64245f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor\n",
      "Best Score: 0.9661141355459152\n",
      "Best Parameters: {'model__max_depth': 23, 'model__min_samples_leaf': 5, 'model__n_estimators': 10}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load JSON configuration\n",
    "with open('C:\\\\Users\\\\91844\\\\Desktop\\\\algorithm1.json') as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = config['design_state_data']['session_info']['dataset']\n",
    "if not os.path.isfile(dataset_path):\n",
    "    raise FileNotFoundError(f\"Dataset file not found: {dataset_path}\")\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Encode categorical 'species' column if it exists\n",
    "if 'species' in df.columns:\n",
    "    df['species'] = LabelEncoder().fit_transform(df['species'])\n",
    "\n",
    "# Extract target and features information\n",
    "target_column = config['design_state_data']['target']['target']\n",
    "prediction_type = config['design_state_data']['target']['type']\n",
    "features = config['design_state_data']['feature_handling']\n",
    "\n",
    "# Handle missing values and preprocessing\n",
    "for feature_name, feature_information in features.items():\n",
    "    if feature_information['is_selected']:\n",
    "        if feature_information['feature_variable_type'] == 'numerical':\n",
    "            strategy_used = feature_information['feature_details']['impute_with'].lower()\n",
    "            if strategy_used == 'average of values':\n",
    "                strategy_used = 'mean'  # Map 'average of values' to 'mean'\n",
    "            elif strategy_used not in ['mean', 'median', 'most_frequent', 'constant']:\n",
    "                raise ValueError(f\"Invalid imputation strategy '{strategy_used}' for feature '{feature_name}'\")\n",
    "            impute_value = feature_information['feature_details'].get('impute_value')  # Get impute_value if needed\n",
    "            imputer = SimpleImputer(strategy=strategy_used, fill_value=impute_value)\n",
    "            df[feature_name] = imputer.fit_transform(df[[feature_name]])\n",
    "        elif feature_information['feature_variable_type'] == 'text':\n",
    "            # Handle text feature as needed (e.g., tokenize and hash)\n",
    "            pass  # Add your text preprocessing logic here if required\n",
    "\n",
    "# Split data\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Feature reduction (if applicable)\n",
    "if config['design_state_data']['feature_reduction']['feature_reduction_method'] == 'Tree-based':\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=int(config['design_state_data']['feature_reduction']['num_of_trees']),\n",
    "        max_depth=int(config['design_state_data']['feature_reduction']['depth_of_trees'])\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    num_features = int(config['design_state_data']['feature_reduction']['num_of_features_to_keep'])\n",
    "    selected_features = [X.columns[indices[f]] for f in range(num_features)]\n",
    "    X = X[selected_features]\n",
    "\n",
    "# Model selection and hyperparameter tuning\n",
    "algorithms = config['design_state_data']['algorithms']\n",
    "results = {}\n",
    "\n",
    "for algorithm_name, algo_information in algorithms.items():\n",
    "    if algo_information['is_selected']:\n",
    "        if algorithm_name == 'RandomForestRegressor' or algorithm_name == 'RandomForestClassifier':\n",
    "            parameter_grid = {\n",
    "                'model__n_estimators': range(algo_information['min_trees'], algo_information['max_trees'] + 1),\n",
    "                'model__max_depth': range(algo_information['min_depth'], algo_information['max_depth'] + 1),\n",
    "                'model__min_samples_leaf': range(algo_information['min_samples_per_leaf_min_value'], algo_information['min_samples_per_leaf_max_value'] + 1)\n",
    "            }\n",
    "            if algorithm_name == 'RandomForestRegressor':\n",
    "                model = RandomForestRegressor()\n",
    "                scorer = 'r2'  # Use r2 for regression\n",
    "            elif algorithm_name == 'RandomForestClassifier':\n",
    "                model = RandomForestClassifier()\n",
    "                scorer = 'f1_weighted'  # Use F1 score for classification\n",
    "\n",
    "        elif algorithm_name == 'GBTRegressor' or algorithm_name == 'GBTClassifier':\n",
    "            parameter_grid = {\n",
    "                'model__n_estimators': algo_information['num_of_BoostingStages'],\n",
    "                'model__learning_rate': algo_information['learningRate'],\n",
    "                'model__subsample': np.linspace(algo_information['min_subsample'], algo_information['max_subsample'], 5),\n",
    "                'model__min_samples_split': range(algo_information['min_stepsize'], algo_information['max_stepsize'] + 1),\n",
    "                'model__max_depth': range(algo_information['min_depth'], algo_information['max_depth'] + 1)\n",
    "            }\n",
    "            if algorithm_name == 'GBTRegressor':\n",
    "                model = GradientBoostingRegressor()\n",
    "                scorer = 'r2'  # Use r2 for regression\n",
    "            elif algorithm_name == 'GBTClassifier':\n",
    "                model = GradientBoostingClassifier()\n",
    "                scorer = 'f1_weighted'  # Use F1 score for classification\n",
    "\n",
    "        elif algorithm_name == 'DecisionTreeRegressor':\n",
    "            parameter_grid = {\n",
    "                'model__max_depth': range(algo_information['min_depth'], algo_information['max_depth'] + 1),\n",
    "                'model__min_samples_leaf': algo_information['min_samples_per_leaf'],\n",
    "                'model__criterion': ['mse']  # Using Mean Squared Error (MSE) for Decision Tree Regressor\n",
    "            }\n",
    "            model = DecisionTreeRegressor()\n",
    "            scorer = 'r2'  # Use r2 for regression\n",
    "\n",
    "        elif algorithm_name == 'DecisionTreeClassifier':\n",
    "            parameter_grid = {\n",
    "                'model__max_depth': range(algo_information['min_depth'], algo_information['max_depth'] + 1),\n",
    "                'model__min_samples_leaf': algo_information['min_samples_per_leaf'],\n",
    "                'model__criterion': ['entropy' if algo_information['use_entropy'] else 'gini']\n",
    "            }\n",
    "            model = DecisionTreeClassifier()\n",
    "            scorer = 'f1_weighted'  # Use F1 score for classification\n",
    "\n",
    "        elif algorithm_name == 'SVM':\n",
    "            parameter_grid = {\n",
    "                'model__C': algo_information['c_value'],\n",
    "                'model__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "                'model__gamma': ['scale', 'auto'] if algo_information['auto'] else algo_information['custom_gamma_values'],\n",
    "                'model__tol': [algo_information['tolerance']],\n",
    "                'model__max_iter': [algo_information['max_iterations']]\n",
    "            }\n",
    "            model = SVC() if algo_information['linear_kernel'] else SVR()\n",
    "            scorer = 'f1_weighted'  # Use F1 score for classification\n",
    "\n",
    "        elif algorithm_name == 'SGD':\n",
    "            parameter_grid = {\n",
    "                'model__loss': ['log' if algo_information['use_logistics'] else 'modified_huber'],\n",
    "                'model__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                'model__alpha': algo_information['alpha_value'],\n",
    "                'model__tol': [algo_information['tolerance']],\n",
    "                'model__max_iter': [algo_information['max_iterations']],\n",
    "                'model__l1_ratio': np.linspace(algo_information['min_elasticnet'], algo_information['max_elasticnet'], 5)\n",
    "            }\n",
    "            model = SGDClassifier() if algo_information['use_logistics'] else SGDRegressor()\n",
    "            scorer = 'f1_weighted'  # Use F1 score for classification\n",
    "\n",
    "        elif algorithm_name == 'KNN':\n",
    "            parameter_grid = {\n",
    "                'model__n_neighbors': algo_information['k_value'],\n",
    "                'model__weights': ['distance' if algo_information['distance_weighting'] else 'uniform'],\n",
    "                'model__algorithm': [algo_information['neighbour_finding_algorithm']],\n",
    "                'model__p': [algo_information['p_value']],\n",
    "                'model__n_jobs': [algo_information['parallelism']]\n",
    "            }\n",
    "            model = KNeighborsClassifier() if prediction_type == 'classification' else KNeighborsRegressor()\n",
    "            scorer = 'f1_weighted' if prediction_type == 'classification' else 'r2'\n",
    "\n",
    "        elif algorithm_name == 'ExtraRandomTrees':\n",
    "            parameter_grid = {\n",
    "                'model__n_estimators': algo_information['num_of_trees'],\n",
    "                'model__max_features': ['sqrt', 'log2'],\n",
    "                'model__max_depth': algo_information['max_depth'],\n",
    "                'model__min_samples_leaf': algo_information['min_samples_per_leaf'],\n",
    "                'model__n_jobs': [algo_information['parallelism']]\n",
    "            }\n",
    "            model = ExtraTreesClassifier() if prediction_type == 'classification' else ExtraTreesRegressor()\n",
    "            scorer = 'f1_weighted' if prediction_type == 'classification' else 'r2'\n",
    "\n",
    "        elif algorithm_name == 'NeuralNetwork':\n",
    "            parameter_grid = {\n",
    "                'model__hidden_layer_sizes': algo_information['hidden_layer_sizes'],\n",
    "                'model__activation': [algo_information['activation']],\n",
    "                'model__alpha': [algo_information['alpha_value']],\n",
    "                'model__max_iter': [algo_information['max_iterations']],\n",
    "                'model__tol': [algo_information['convergence_tolerance']],\n",
    "                'model__early_stopping': [algo_information['early_stopping']],\n",
    "                'model__solver': [algo_information['solver']],\n",
    "                'model__shuffle': [algo_information['shuffle_data']],\n",
    "                'model__learning_rate_init': [algo_information['initial_learning_rate']],\n",
    "                'model__batch_size': ['auto' if algo_information['automatic_batching'] else 'None'],\n",
    "                'model__beta_1': [algo_information['beta_1']],\n",
    "                'model__beta_2': [algo_information['beta_2']],\n",
    "                'model__epsilon': [algo_information['epsilon']],\n",
    "                'model__power_t': [algo_information['power_t']],\n",
    "                'model__momentum': [algo_information['momentum']],\n",
    "                'model__nesterovs_momentum': [algo_information['use_nesterov_momentum']]\n",
    "            }\n",
    "            model = MLPClassifier() if prediction_type == 'classification' else MLPRegressor()\n",
    "            scorer = 'f1_weighted' if prediction_type == 'classification' else 'r2'\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer()),\n",
    "            ('model', model)\n",
    "        ])\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=pipeline, param_grid=parameter_grid, cv=5, n_jobs=-1, scoring=scorer)\n",
    "        grid_search.fit(X, y)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X)\n",
    "        if algorithm_name in ['RandomForestRegressor', 'GBTRegressor', 'DecisionTreeRegressor', 'LinearRegression',\n",
    "                              'RidgeRegression', 'LassoRegression', 'ElasticNetRegression', 'XGBoost', 'KNN', 'Extra Random Trees', 'Neural Network']:\n",
    "            score = r2_score(y, y_pred)\n",
    "        elif algorithm_name in ['RandomForestClassifier', 'GBTClassifier', 'DecisionTreeClassifier', 'LogisticRegression',\n",
    "                                'SVM', 'SGD']:\n",
    "            score = f1_score(y, y_pred, average='weighted')\n",
    "\n",
    "        results[algorithm_name] = {\n",
    "            'Best Model': best_model,\n",
    "            'Best Parameters': grid_search.best_params_,\n",
    "            'Best Score': score\n",
    "        }\n",
    "\n",
    "# Print results best models\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Best Score: {metrics['Best Score']}\")\n",
    "    print(f\"Best Parameters: {metrics['Best Parameters']}\")\n",
    "    print(\"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647b6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
